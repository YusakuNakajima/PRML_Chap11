---
marp: true
theme: default
paginate: true
---

# 目次

## 11.1 サンプリングアルゴリズム
- 11.1.1 一般的な分布
- 11.1.2 棄却サンプリング
- 11.1.3 適応的棄却サンプリング
- 11.1.4 重点サンプリング
- 11.1.5 SIR
- 11.1.6 サンプリングとEMアルゴリズム
---
# 目次

## 11.2 マルコフ連鎖モンテカルロ(MCMC)
- 11.2.1 マルコフ連鎖とメトロポリス法
- 11.2.2 メトロポリス・ヘイスティング法

## 11.3 ギブスサンプリング

## 11.4 スライスサンプリング
---
# 目次

## 11.5 ハイブリッドモンテカルロ(統計力学との融合)
- 11.5.1 力学系
- 11.5.2 ハイブリッドモンテカルロ

## 11.6 分配関数の推定
---

# 11.1 サンプリングアルゴリズム
- **第10章**: 決定論的近似に基づく推論アルゴリズム
  - 変分ベイズ法
  - 期待伝播法
- これらの方法は解析的手法を用いて近似推論を行う
- ほとんどの実用的な確率モデルにおいて、正確な推論は困難
- **第11章**: 数値サンプリングに基づく近似推論法
  - モンテカルロ法
  - サンプリングアルゴリズムの詳細
- 近似法としてモンテカルロ法を使用

---

# 近似推論の目的

- 期待値を評価するために事後分布を使用
- 関数 $f(z)$ の期待値 $E[f]$ を求める
- 連続変数の場合は積分、離散変数の場合は総和

---

# 期待値の評価

- 連続変数の場合: $E[f] = \int f(z)p(z) \, dz$
- 離散変数の場合: 総和に置き換え

---

# サンプリング法の基本アイデア

- 分布 $p(z)$ から独立にサンプル $z^{(l)}$ を取得 ($l = 1,...,L$)
- 期待値 $E[f]$ を有限の総和で近似
- 推定量 $f \approx \frac{1}{L} \sum_{l=1}^{L} f(z^{(l)})$

---

# 推定量の性質

- サンプル $z^{(l)}$ が分布 $p(z)$ から抽出されている場合、$E[\hat{f}] = E[f]$
- 推定量の分散 $\text{var}[\hat{f}] = \frac{1}{L} E[(f - E[f])^2]$
- $z$ の次元に依存せず、少数のサンプルで高精度が可能

---

# サンプリングの課題

- サンプルが独立でない場合、実効サンプルサイズが小さくなる
- $f(z)$ と $p(z)$ の相互関係によって必要なサンプルサイズが増加

---

# グラフィカルモデルとサンプリング

- 有向グラフの場合、祖先サンプリングアプローチを使用
- 結合分布 $p(z) = \prod_{i=1}^{M} p(z_i | pa_i)$
- 各ノードの条件付き分布からサンプルを抽出

---

# 観測値を持つ有向グラフ

- 論理サンプリングアプローチ
- サンプル値と観測値が一致する場合にサンプルを保持
- 観測変数の数が増えると受け入れ確率が急速に減少

---

# 無向グラフとサンプリング

- ワンパスサンプリング戦略は存在しない
- ギブスサンプリングなどの計算コストの高い手法が必要

---

# 周辺分布からのサンプリング

- 結合分布 $p(u, v)$ からサンプルを取得
- 各サンプルで $v$ の値を無視することで周辺分布 $p(u)$ からサンプルを取得

---

